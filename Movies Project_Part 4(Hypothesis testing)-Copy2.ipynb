{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d8f2747",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f2f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "\n",
    "import pymysql\n",
    "pymysql.install_as_MySQLdb()\n",
    "from sqlalchemy.types import *\n",
    "from sqlalchemy_utils import create_database, database_exists\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccac6c2e",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9c38c1",
   "metadata": {},
   "source": [
    "**Connecting to Mysql database**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb8636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a connection string using credentials following this format:\n",
    "# connection = \"dialect+driver://root:root@host:port/database\"\n",
    "database_name = \"Movies\"\n",
    "connection_str = f\"mysql+pymysql://root:root@localhost/{database_name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d2dc6e",
   "metadata": {},
   "source": [
    "**Creating the engine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167b85c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the sqlalchemy create_engine class\n",
    "engine = create_engine(connection_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b082bfa",
   "metadata": {},
   "source": [
    "**Assigning datatype to each column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f386cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate max string lengths for object columns\n",
    "imdb_id_len = tmdb_results_combined_final_df['imdb_id'].fillna('').map(len).max()\n",
    "certification_len = tmdb_results_combined_final_df['certification'].fillna('').map(len).max()\n",
    "\n",
    "\n",
    "# Use 1 + the max_str_len for object columns\n",
    "# Create a schema dictonary using Sqlalchemy datatype objects\n",
    "df_schema = {\n",
    "    'imdb_id': String(imdb_id_len+1), \n",
    "    'budget':Float(),\n",
    "    'revenue':Float(),\n",
    "    'certification': String(certification_len+1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b866f4e",
   "metadata": {},
   "source": [
    "**Savig the dataframe to a database table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb27680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dataframe to an sql table\n",
    "# with appropriate datatypes and set index=False\n",
    "tmdb_results_combined_final_df.to_sql('tmdb_data',\n",
    "              engine, \n",
    "              dtype=df_schema,\n",
    "              if_exists='replace',\n",
    "              index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d893232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the sqlalchemy engine to update the table and set imdb_id as the primary key\n",
    "engine.execute('ALTER TABLE tmdb_data ADD PRIMARY KEY (`imdb_id`);')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df6f7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 rows of the table using an SQL query\n",
    "q = \"\"\"\n",
    "SELECT * \n",
    "FROM tmdb_data LIMIT 5\n",
    ";\"\"\"\n",
    "pd.read_sql(q, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6d3f0b",
   "metadata": {},
   "source": [
    "# Hypothesis Testing\n",
    "\n",
    "\n",
    "Stakeholder Questions\n",
    "For each question:\n",
    "\n",
    "The stakeholder has requested statistical tests to obtain mathematically-supported answers to their questions.\n",
    "They would like to know if a statistically significant difference exists for each hypothesis.\n",
    "They would like to know the p-value of the test.\n",
    "They would like a visualization that supports the findings of the test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac864d3d",
   "metadata": {},
   "source": [
    "### Does the MPAA rating of a movie ('G', 'NC-17', 'NR', 'PG', 'PG-13', or 'R') affect how much revenue the movie generates?\n",
    "\n",
    "\n",
    "\n",
    "**Null Hypothesis:**\n",
    "\n",
    "he MPAA rating of a movie ('G', 'NC-17', 'NR', 'PG', 'PG-13', or 'R') DOES NOT affect how much revenue the movie generates?\n",
    "\n",
    "**Alternative Hypothesis:**\n",
    "\n",
    "The MPAA rating of a movie ('G', 'NC-17', 'NR', 'PG', 'PG-13', or 'R') DOES affect how much revenue the movie generates\n",
    "\n",
    "   - **Type of Data:**   \n",
    "        Numeric\n",
    "        \n",
    "        \n",
    "   - **Number of samples:**   \n",
    "   Multiple samples\n",
    "   \n",
    "   \n",
    "   - **Test type:**\n",
    "   \n",
    "   If parametric: ANOVA and/or Tukey\n",
    "   \n",
    "   If nonparametric: Kruskal-Wallis\n",
    "   \n",
    "   \n",
    "  \n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f9091b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 rows of the table using an SQL query\n",
    "q = \"\"\"\n",
    "SELECT revenue, certification\n",
    "FROM tmdb_data \n",
    "WHERE revenue > 0 AND certification IS NOT NULL\n",
    ";\"\"\"\n",
    "df =pd.read_sql(q, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffe569d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0225e0",
   "metadata": {},
   "source": [
    "## Assumption Tests\n",
    "\n",
    "**Test for significant Outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546c70f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['certification'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cba20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {}\n",
    "for certification in df[\"certification\"].unique():\n",
    "    temp = df.loc[df[\"certification\"]== certification,\"revenue\"]\n",
    "    groups[certification ]= temp\n",
    "groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d152ca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for certification, revenue in groups.items():\n",
    "    outliers = np.abs(stats.zscore(revenue))>3\n",
    "    print(f'Group {certification}: {outliers.sum()} outliers')\n",
    "    groups[certification] = revenue.loc[~outliers]\n",
    "print('All outliers have been removed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afaa3d2",
   "metadata": {},
   "source": [
    "**The test for outliers is satisfied, since all outliers have been removed**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb6c03f",
   "metadata": {},
   "source": [
    "**Test for Normality**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "232513f2",
   "metadata": {},
   "source": [
    "###### Using a loop to obtain group count and pvalues\n",
    "\n",
    "n_results = {}\n",
    "for certification, revenue in groups.items():\n",
    "    stat, p = stats.normaltest(revenue)\n",
    "    n_results[certification] = {\"n\":len(revenue), \"p\":p}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89396c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a dataframe created from the norm_results dictonary and transpose it \n",
    "pd.DataFrame(norm_results).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51854fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and display a dataframe created from the norm_results dictonary and transpose it \n",
    "norm_results_df = pd.DataFrame(norm_results).T\n",
    "# Add a column to indicate if the group pvalue was significant or not\n",
    "norm_results_df['sig?'] = norm_results_df['p'] < .05\n",
    "\n",
    "# Display the dataframe\n",
    "norm_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f85036a",
   "metadata": {},
   "source": [
    "- We have large enough groups (each n>20) that we can safely disregard the assumption of normality, even though:\n",
    "- The groups do NOT come from normal distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fcb9cb",
   "metadata": {},
   "source": [
    "**Assumption Equal Variance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876de1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the test and display the results\n",
    "statistic, pvalue = stats.levene(*groups.values())\n",
    "if pvalue < alpha:\n",
    "    print(f'The p-value for the test was {pvalue}')\n",
    "    print(f'It was < the alpha value of {alpha}, so')\n",
    "    print(ha_desc)\n",
    "    print(ha)\n",
    "else:\n",
    "    print(f'The p-value for the test was {pvalue}')\n",
    "    print(f'It was > the alpha value of {alpha}, so')\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c77182a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c132b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a36241b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ebda18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
